#!/usr/bin/env python
"""
Calculate the efficiency and purity of seed candidates.
Plot the eta and pT distributions of the input hits,
as well as the efficiency as a function of pT and eta.

good_particles: 
    1) has at least 3 hits in different layers 
    2)  has minimum number of hits
matched_particles:
    1) at least one seed is matched to that particle

efficiency = n_matched_particles / n_good_particles

purity = n_seeds_with_all-hits-from-the-same-particle / n_seeds
"""
import argparse
import pickle
import glob
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from heptrkx import utils
from heptrkx import master
from heptrkx import pairwise
from heptrkx import seeding
from heptrkx.utils_math import ratio_error


def get_ratio(x_vals, y_vals):
    res = [x/y if y!=0 else 0.0 for x,y in zip(x_vals, y_vals)]
    return res[1:]


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='calculate seeding efficiency')
    add_arg = parser.add_argument
    add_arg('candiate',  help="seeding candidates")
    add_arg('output',  help="output name")
    add_arg('-d', '--data',  help="original tracking ML data",
            default='/global/project/projectdirs/m3443/usr/xju/heptrkx/codalab/inputs/train_all')
    # minimum number of hits for a particle to be a good(reconstructable) particle
    add_arg('--min-hits', type=int,
        help='minimum number of hits for a particle to be reconstructable', default=5)
    # apply the same hit selections as that applied when making the seeds
    # then only use these hits to define the "total true particles"
    add_arg('--no-noise', action='store_true', help='Exclude noise hits')
    add_arg('--eta-cut', default=5.0, type=float, help='eta threshold')
    add_arg('--layers', nargs='?',
            help='use hits in the specific layers', default=None, const='7,8,9')
    add_arg('-v', '--verbose', action='store_true', help='print debug info')

    args = parser.parse_args()
    seed_candidates = args.candiate
    data_input_dir = args.data
    output = args.output
    no_noise = args.no_noise
    min_hits = args.min_hits
    layers = args.layers
    verbose = args.verbose

    if args.layers is not None:
        print("select hits in following layers")
        print(layers)
        layers = [int(x) for x in args.layers.split(',')]
    
    df_seed = seeding.read_triplets(seed_candidates)
    evt_list = np.unique(df_seed.evtid)
    tot_evts = evt_list.shape[0]
    print("Total {} events".format(tot_evts))
    if tot_evts < 1:
        exit(1)
    # print(df_seed.columns)

    # collect following info for each event
    # evtid, n_hits, n_particles, n_matched_particles, 
    # n_seeds, n_true_seeds_with_hits_at_same_layer, n_true_seeds
    summary_info = []

    particle_pT_list = []
    matched_particle_pT_list = []
    particle_eta_list = []
    matched_particle_eta_list = []
    for evtid in evt_list:
        if verbose:
            print("Processing Event {}".format(evtid))

        event = master.Event(data_input_dir)
        if not event.read(evtid):
            print("event {} does not have truth info".format(evtid))
            continue
        # else:
        #     print(event.hits.head())

        # hits = utils.select_hits(event, no_noise, eta_cut=1.2)
        hits = utils.select_hits(event, no_noise, eta_cut=args.eta_cut)
        all_particles = np.unique(hits.particle_id).shape[0]
        all_hits = hits.shape[0]
        if verbose:
            print("Total particles: {}, with {} hits".format(all_particles, all_hits))

        aa = hits.groupby(['particle_id'])['hit_id'].count()
        total_particles = aa[aa > min_hits].index
        total_particles = total_particles[total_particles != 0]
        n_total_particles = total_particles.shape[0]
        if verbose:
            print("Event {} has {} particles with minimum of {} hits".format(
                evtid, n_total_particles, min_hits))

        df = df_seed[df_seed.evtid == evtid]
        if verbose:
            print("Event {} has {} seed candidates".format(evtid, df.shape[0]))

        if layers is not None:
            ## now select the hits in specified layers
            hits = hits[hits.layer.isin(layers)]

        # particles leaving 3 hits in three layers
        bb = hits.groupby(['particle_id'])['layer'].count()
        good_particles = bb[(bb > 2) & (aa > min_hits)].index
        good_particles = good_particles[good_particles != 0]

        if verbose:
            print("Event {} has {} particles leaving hits at inner 3 layers".format(
                evtid, good_particles.shape[0]))
            good_particles_pT = np.unique(hits[hits.particle_id.isin(good_particles) \
                                    & hits.pt.abs() >= 1].particle_id)
            print("Event {} has {} particles leaving hits at inner 3 layers, with pT > 1 GeV".format(
                evtid, good_particles_pT.shape[0]))
        df1 = df.merge(hits, left_on='h1', right_on='hit_id', how='left')
        df2 = df.merge(hits, left_on='h2', right_on='hit_id', how='left')
        df3 = df.merge(hits, left_on='h3', right_on='hit_id', how='left')
        p1 = df1.particle_id.astype('int64')
        p2 = df2.particle_id.astype('int64')
        p3 = df3.particle_id.astype('int64')

        n_total_seeds = df.shape[0]
        true_seeds_dup = p1[(p1 != 0) & (p1==p2) & (p2==p3)]
        n_true_seeds_dup = true_seeds_dup.shape[0]
        true_seeds = p1[(p1 != 0) & (p1==p2) & (p2==p3) & (df1.layer != df2.layer) & (df1.layer != df3.layer) & (df2.layer != df3.layer)]
        n_true_seeds = true_seeds.shape[0]

        unique_true_seeds = np.unique(true_seeds)
        n_unique_true_seeds = unique_true_seeds.shape[0]

        summary_info.append((evtid, hits.shape[0], good_particles.shape[0], unique_true_seeds.shape[0],
                            n_total_seeds, true_seeds_dup.shape[0], true_seeds.shape[0]))

        if verbose:
            print("{} particles matched".format(n_unique_true_seeds))
            print("Fraction of duplicated seeds: {:.2f}%".format(100 - n_unique_true_seeds*100/n_true_seeds))
            print("Purity: {:.2f}%".format(n_true_seeds*100./n_total_seeds))
            print("Efficiency: {:.2f}%".format(n_unique_true_seeds*100./good_particles.shape[0]))

        df_unique_true_seeds = pd.DataFrame(unique_true_seeds, columns=['particle_id'])
        df_unique_true_seeds = df_unique_true_seeds.merge(event.particles, on='particle_id', how='left')
        df_total_particles = pd.DataFrame(good_particles, columns=['particle_id'])
        df_total_particles = df_total_particles.merge(event.particles, on='particle_id', how='left')

        particle_pT_list.append(df_total_particles.pt)
        matched_particle_pT_list.append(df_unique_true_seeds.pt)
        particle_eta_list.append(df_total_particles.peta)
        matched_particle_eta_list.append(df_unique_true_seeds.peta)

    # summarize
    df_summary = pd.DataFrame(data=summary_info,
                        columns=['evtid', 'n_hits', 'n_particles', 'n_matched_particles',
                            'n_seeds', 'n_true_seeds_dup', 'n_true_seeds'
                        ])
    tot_particles = np.sum(df_summary.n_particles)
    tot_matched_particles = np.sum(df_summary.n_matched_particles)
    tot_seeds = np.sum(df_summary.n_seeds)
    tot_true_seeds = np.sum(df_summary.n_true_seeds)
    tot_true_seeds_tot = np.sum(df_summary.n_true_seeds_dup)

    print("Summary")
    print("Total {} events".format(tot_evts))
    print("On average: {} hits per event and {} particles per event".format(
        np.sum(df_summary.n_hits)/tot_evts,
        np.sum(df_summary.n_particles)/tot_evts,
        ))
    print("On average: {} seeds per event. \n\t{} ({:.2f}%)true seeds, "
          "\t{} ({:.2f}%) true seeds after removing seeds with two hits being the same layer"
          "\ta factor of {:.1f} duplicated seeds".format(
            tot_seeds/tot_evts, 
            tot_true_seeds_tot/tot_evts, 100*tot_true_seeds_tot/tot_seeds,
            tot_true_seeds/tot_evts, 100*tot_true_seeds/tot_true_seeds_tot,
            tot_true_seeds/tot_matched_particles,
            ))
    print("Purity: {:.1f} +/- {:.2f}%".format(*ratio_error(tot_true_seeds, tot_seeds, True)))
    print("Efficiency: {:.1f} +/- {:.2f}%".format(*ratio_error(tot_matched_particles, tot_particles, True)))

    tot_pt = np.concatenate(particle_pT_list)
    matched_pt = np.concatenate(matched_particle_pT_list)
    tot_eta = np.concatenate(particle_eta_list)
    matched_eta = np.concatenate(matched_particle_eta_list)
    df_tot = pd.DataFrame({'pT': tot_pt, 'eta': tot_eta})
    df_matched = pd.DataFrame({"pT": matched_pt, "eta": matched_eta})
    # save the info
    with pd.HDFStore(output+".h5", 'w') as store:
        store['summary'] = df_summary
        store['tot'] = df_tot
        store['matched'] = df_matched

    pT_bins = [-0.1, 0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.5, 1.9, 2.4, 5]
    eta_bins = [-5, -3, -2.4, -2.0, -1.6, -1.2, -0.8, -0.4, 0, 0.4, 0.8, 1.2, 1.6, 2.0, 2.4, 3, 5]
    # efficiency as function of pT
    hist_configs = {
        'bins': pT_bins,
        'histtype': 'step',
        'lw': 2,
        'log': True
    }
    fig, ax = plt.subplots(figsize=(8, 8), constrained_layout=True)
    tot_vals, bins, _ = ax.hist(tot_pt, label='total', **hist_configs)
    sel_vals, bins, _ = ax.hist(matched_pt, label='selected', **hist_configs)
    plt.xlabel("pT [GeV]")
    plt.ylabel("number of particles")
    plt.legend()
    plt.savefig(output+"_pT.png", bbox_inches='tight')

    plt.clf()
    ratio = get_ratio(sel_vals, tot_vals)
    xvals = [0.5*(x[0]+x[1]) for x in pairwise(bins)][1:]
    line_configs = {'lw': 2}
    lstype = '-o'
    plt.plot(xvals, ratio, lstype, **line_configs)
    for i,j in zip(xvals, ratio):
        plt.text(i, j*1.05, "{:.2f}".format(j))

    plt.xlabel("pT [GeV]")
    plt.ylabel("Efficiency")
    plt.savefig(output+"_eff_pT.png", bbox_inches='tight')
    plt.clf()

    ## make eta bins
    hist_configs = {
        'bins': eta_bins,
        'histtype': 'step',
        'lw': 2,
        'log': True,
        "range": (-5, 5),
    }
    fig, ax = plt.subplots(figsize=(8, 8), constrained_layout=True)
    tot_vals, bins, _ = ax.hist(tot_eta, label='total', **hist_configs)
    sel_vals, bins, _ = ax.hist(matched_eta, label='selected', **hist_configs)
    plt.legend()
    plt.savefig(output+"_eta.png", bbox_inches='tight')
    plt.clf()
    ratio = get_ratio(sel_vals, tot_vals)
    xvals = [0.5*(x[0]+x[1]) for x in pairwise(bins)][1:]
    line_configs = {'lw': 2}
    lstype = '-o'
    plt.plot(xvals, ratio, lstype, **line_configs)
    for i,j in zip(xvals, ratio):
        plt.text(i, j*1.05, "{:.2f}".format(j))

    plt.xlabel("Eta")
    plt.ylabel("Efficiency")
    plt.savefig(output+"_eff_eta.png", bbox_inches='tight')
    plt.clf()