#!/usr/bin/env python
"""
Read Track ML dataseta and convert to HDF5 with the hits under consideration
In between, add local cluster info for each hit
"""

import argparse
import os
import numpy as np
import pandas as pd

from heptrkx.dataset import event as master
from heptrkx.utils import is_df_there


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='product event data with hits of interests')
    add_arg = parser.add_argument
    add_arg('nevts', type=int, help='number of events')
    add_arg('--outdir', help='output directory', default='.')
    add_arg('--input-dir', 
            default='/global/cscratch1/sd/xju/heptrkx/codalab/inputs/train_all',
            help='input trackML data')
    add_arg('--det-conf', help="detector configuration",
            default='/global/cfs/projectdirs/m3443/usr/xju/heptrkx/codalab/inputs/detector.csv')
    add_arg('--start-evt-id', default=21001, type=int)
    add_arg('--mpi', action='store_true', help='use MPI')
    add_arg('--layers', default="7, 8, 9, 10, 24, 25, 26, 27, 40, 41", help='layers of interest', const="-1")

    args = parser.parse_args()

    nevts = args.nevts
    outdir = args.outdir
    input_dir = args.input_dir
    det_conf = args.det_conf
    start_evt_id = args.start_evt_id
    use_mpi = args.mpi
    layers = [int(x) for x in args.layers.split(',')]

    if use_mpi:
        try:
            from mpi4py import MPI
            comm = MPI.COMM_WORLD
            size = comm.Get_size()
            rank = comm.Get_rank()
        except ImportError:
            rank = 0
            size = 1
    else:
        rank = 0
        size =1

    if rank == 0:
        evtids = list(range(nevts))
        # check if the file is there and remove those
        evtids = [x.tolist() for x in np.array_split(evtids, size)]
    else:
        evtids = None
    
    if use_mpi:
        evtids = comm.scatter(evtids, root=0)
    else:
        evtids = evtids[0]
    
    
    if size == 1:
        outname = os.path.join(outdir, 'evt{}-{}events.h5'.format(start_evt_id, nevts))
    else:
        outname = os.path.join(outdir, 'evt{}-{}events-{:03}.h5'.format(start_evt_id, nevts, rank))

    if is_df_there(outname):
        print("{} is there".format(outname))
        exit(0)
    print(rank, "has", len(evtids), "jobs")

    with pd.HDFStore(outname, 'w') as store:
        event = master.Event(input_dir)
        module_getter = master.module_info(det_conf)

        for idx in evtids:
            evtid = start_evt_id + idx
            if event.read(evtid):
                if layers[0] >= 0:
                    event.filter_hits(layers)
                event.cluster_info(det_conf)
                store['evt{}'.format(evtid)] = event.hits
                
    print(rank, "finished")