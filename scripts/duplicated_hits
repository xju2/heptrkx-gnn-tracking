#!/usr/bin/env python
"""
Calculate the fraction of particles that have at least one layer
in that more than one hit is recorded.
Only particles at specified _layers_ are considered.
"""
import os
import argparse
import glob
import re

import multiprocessing as mp
from functools import partial

import numpy as np
import matplotlib.pyplot as plt

from heptrkx.dataset import event as master
from heptrkx.utils import load_yaml


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='plot number of duplicated hits for each track.')
    add_arg = parser.add_argument
    add_arg('outname', help='output plot name')
    add_arg('--layers', default="7, 8, 9, 10, 24, 25, 26, 27, 40, 41", help='layers of interest')
    add_arg('--evts', type=int, help='number of events', default=10)
    add_arg('--start-evt-id', default=21001, type=int)
    add_arg('--input-dir', 
        default='/global/cscratch1/sd/xju/heptrkx/codalab/inputs/train_all',
        help='input trackML data')
    add_arg("--works", default=1, type=int, help='number of workers')

    args = parser.parse_args()
    outname = args.outname
    event = master.Event(args.input_dir)
    layers = [int(x) for x in args.layers.split(',')]

    num_duplicated_hits = []
    for ievt in range(args.evts):
        evtid = args.start_evt_id + ievt
        event.read(evtid)
        event.filter_hits(layers)
        event.remove_noise_hits()
        num_duplicated_hits.append(event.count_duplicated_hits())

    diff = np.concatenate(num_duplicated_hits)
    nbins = 11
    arr = plt.hist(diff, bins=nbins, range=(-0.5, 10.5), density=True)
    for i in range(nbins):
        plt.text(arr[1][i], arr[0][i], "{:.3f}".format(arr[0][i]))
    plt.xlabel("number of duplicated hits")
    plt.savefig(outname+".pdf")
