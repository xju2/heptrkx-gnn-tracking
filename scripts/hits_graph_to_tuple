#!/usr/bin/env python
import os
import numpy as np
import pandas as pd
from functools import partial

from heptrkx.nx_graph import utils_data
from heptrkx.nx_graph import prepare

from heptrkx.datasets.graph import load_graph
import multiprocessing as mp

def process_event(evt_id, input_dir, n_sections, output, bidirection):
    saver_fn = prepare.get_networkx_saver(output)
    for isec in range(n_sections):
        input_name = os.path.join(
            input_dir,
            'event{:09d}_g{:03d}.npz'.format(evt_id, isec))
        ID_input_name = os.path.join(
            input_dir,
            'event{:09d}_g{:03d}_ID.npz'.format(evt_id, isec))
        if os.path.exists(input_name) and not saver_fn(evt_id, isec, None):
            try:
                with np.load(ID_input_name) as f:
                    IDs = pd.DataFrame(data=f['ID'], columns=['ID'])
            except ValueError:
                print(ID_input_name)
                raise

            graph = utils_data.hitsgraph_to_nx(
                load_graph(input_name), IDs=IDs, bidirection=bidirection)

            saver_fn(evt_id, isec, graph)

if __name__ == "__main__":
    import numpy as np
    import glob
    import re

    from graph_nets import utils_np
    import argparse

    parser = argparse.ArgumentParser(description='Train nx-graph with configurations')
    add_arg = parser.add_argument
    add_arg('config', help="job configuration")
    add_arg('-b', '--bidirection', action='store_true')
    add_arg('-i', '--itask', type=int, default=0)
    args = parser.parse_args()

    from heptrkx import load_yaml
    config = load_yaml(args.config)
    input_dir = config['data']['input_hitsgraph_dir']
    base_dir = os.path.join(input_dir,'event{:09d}_g{:03d}.npz')

    # find number of files, section IDs in hitgraphs directory
    file_patten = os.path.join(input_dir, 'event*_g000.npz')
    print(file_patten)
    all_files = glob.glob(file_patten)
    n_events = len(all_files)
    evt_ids = sorted([int(re.search('event([0]*)([0-9]*)_g000.npz', os.path.basename(x)).group(2))
               for x in all_files])

    section_patten = base_dir.format(evt_ids[0], 0).replace('_g000', '_g[0-9]*[0-9]*[0-9]')
    n_sections = len(glob.glob(section_patten))
    n_total = n_events*n_sections
    print("Total Events: {} with {} sections, total {} files ".format(
        n_events, n_sections, n_total))

    output = config['data']['output_nxgraph_dir']
    if not os.path.exists(output):
        os.makedirs(output)


    print("Input directory: {}".format(input_dir))
    print("Output directory: {}".format(output))

    import time
    start_time = time.time()

    # split all evt_ids to n_tasks and n_workers
    n_tasks = config['data']['n_tasks']
    n_workers = config['data']['n_workers']
    evt_ids_split = np.array_split(evt_ids, n_tasks)[args.itask]

    # invoke workers
    with mp.Pool(processes=n_workers) as pool:
        pp_fn = partial(process_event,
                        input_dir=input_dir,
                        n_sections=n_sections,
                        output=output,
                        bidirection=args.bidirection)
        pool.map(pp_fn, evt_ids_split)
