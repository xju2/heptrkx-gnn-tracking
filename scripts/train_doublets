#!/usr/bin/env python
"""
Use MLPs to classify doublets/pairs.
Inputs are the pre-doublets
"""


if __name__ == "__main__":
    import os
    import argparse

    import pandas as pd
    import numpy as np
    import time

    from bisect import bisect
    import tensorflow as tf
    from tensorflow import keras

    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import precision_recall_curve

    from heptrkx.nx_graph import shadow_model
    from heptrkx.utils import load_yaml, layer_pairs
    from heptrkx.nx_graph.utils_plot import plot_metrics


    parser = argparse.ArgumentParser(description='Train a NN for each layer pair using pre-doublets')
    add_arg = parser.add_argument
    add_arg('input', help='training inputs')
    add_arg('config', help='training configurations')
    add_arg('pair_idx', nargs='?', type=int, default=0, help='which layer pair')
    add_arg('--resume-train',  action='store_true')
    add_arg('--in-eval', action='store_true')
    add_arg('--truth-var', default='solution', help='true variable')
    args = parser.parse_args()

    config = load_yaml(args.config)
    train_cfg = config['doublet_training']

    batch_size = train_cfg['batch_size']
    epochs = train_cfg['epochs']
    output_dir = train_cfg['model_output_dir']
    pair_idx = args.pair_idx
    model_name = train_cfg['model']
    file_name = args.input
    print("Training File Name: {}".format(file_name))

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    ## save checkpoints
    checkpoint_path = os.path.join(output_dir, "modelpair{:03d}.ckpt".format(pair_idx))
    checkpoint_dir = os.path.dirname(checkpoint_path)

    pair_info = layer_pairs[pair_idx]

    outname = os.path.join(output_dir, 'info{:03d}-{}-{}.txt'.format(pair_idx, *pair_info))

    if os.path.exists(checkpoint_path+".index") \
       and not args.resume_train \
       and os.path.exists(outname):
        print("model is trained and evaluated")
        exit()

    # same model for everyone
    model = getattr(shadow_model, model_name)()

    if os.path.exists(checkpoint_path+".index") and (args.resume_train or args.in_eval):
        print("Resume previous training")
        model.load_weights(checkpoint_path)

    model.compile(optimizer='adam',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

    print("Model is compiled. Start to read training data")
    truth_var = 'solution'
    features = train_cfg['features']
    all_var = features + ['solution']
    with pd.HDFStore(file_name, mode='r') as store:
        t1 = time.time()
        df_input = store['data']
        t2 = time.time()
        df_input = df_input[all_var]
        t3 = time.time()
        print("Time to read background data: {:.0f} seconds".format(t2-t1))
        print("Time to convert format: {:.0f} seconds".format(t3-t2))
    print("ready for training")

    all_inputs  = df_input[features].values
    all_targets = df_input[[truth_var]].values
    n_total = all_inputs.shape[0]
    n_true = np.sum(all_targets)
    n_fake = n_total - n_true
    print("All Entries: {:,}".format(n_total))
    print("True: {:,}".format(n_true))
    print("Fake: {:,}".format(n_fake))

    n_training = int(n_total*0.8)
    n_validating = int(n_total*0.1)

    # transform all inputs
    scaler = StandardScaler()
    all_inputs_normed = scaler.fit_transform(all_inputs)

    inputs = all_inputs_normed[:n_training, :]
    targets = all_targets[:n_training, :]

    x_val = all_inputs_normed[n_training:n_training+n_validating, :]
    y_val = all_targets[n_training:n_training+n_validating, :]
    x_test = all_inputs_normed[n_training+n_validating:, :]
    y_test = all_targets[n_training+n_validating:, :]

    if not args.in_eval:
        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0.0001)
        cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,
                                                         save_weights_only=True,
                                                         verbose=1)

        history = model.fit(inputs, targets,
                            epochs=epochs, batch_size=batch_size,
                            validation_data=(x_val, y_val),
                            callbacks = [cp_callback, early_stop],
                            class_weight={0: 1, 1: n_fake/n_true},
                            verbose=1)

    prediction = model.predict(x_test,
                               batch_size=batch_size)

    test_inputs = df_input[n_training+n_validating:]
    test_inputs = test_inputs.assign(prediction=prediction)

    plot_metrics(prediction, y_test,
                 outname=os.path.join(output_dir, 'roc{:03d}_{}-{}.pdf'.format(pair_idx, *pair_info)),
                 off_interactive=True)

    # find a threshold
    y_true = y_test > 0.5
    purity, efficiency, thresholds = precision_recall_curve(y_true, prediction)
    #print(len(purity), len(efficiency), len(thresholds))

    eff_cut = train_cfg['eff_cut']
    ti = bisect(list(reversed(efficiency.tolist())), eff_cut)
    ti = len(efficiency) - ti
    thres = thresholds[ti]
    out = "{} {} {} {th:.4f} {tp:.4f} {fp:.4f} {true} {fake}\n".format(
        pair_idx, *pair_info, th=thres, tp=efficiency[ti], fp=purity[ti],
        true=n_true, fake=n_fake)

    with open(outname, 'a') as f:
        f.write(out)