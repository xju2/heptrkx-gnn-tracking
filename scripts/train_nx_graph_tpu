#!/usr/bin/env python
"""
Training GNN in TPU/GPU/CPU with fixed graph size
Its input is TFRecord
"""
import os
import sys
import argparse
import glob
import re
import time
import random
import functools
# os.environ['TF_AUTO_MIXED_PRECISION_GRAPH_REWRITE_IGNORE_PERFORMANCE'] = '1'

import tensorflow as tf
print(tf.__version__)
# tf.debugging.set_log_device_placement(True)
# config_proto = tf.compat.v1.ConfigProto()

# tf.config.optimizer.set_jit(True)
# tf.config.optimizer.set_experimental_options({
#     # "auto_mixed_precision": True,
# })


import numpy as np
import sklearn.metrics


from graph_nets import utils_tf
from graph_nets import utils_np
import sonnet as snt

from heptrkx.dataset import graph
# from heptrkx.nx_graph.distribute_model import SegmentClassifier
# from heptrkx.nx_graph.model import SegmentClassifier
from heptrkx.nx_graph import get_model
from heptrkx.utils import load_yaml

prog_name = os.path.basename(sys.argv[0])

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Train nx-graph with configurations')
    add_arg = parser.add_argument
    add_arg('config', help='configuration file')
    add_arg('--tpu', help='use tpu', default=None)
    add_arg('--zone', help='gcloud zone for tpu', default='us-central1-b')
    args = parser.parse_args()

    if not os.path.exists(args.config):
        import pkg_resources
        in_config_file = pkg_resources.resource_filename("heptrkx", os.path.join("configs", args.config))
    else:
        in_config_file = args.config
    
    print("reading configration file:", in_config_file)
    all_config = load_yaml(in_config_file)
    config = all_config['gnn_training']
    config_tr = config['parameters']
    use_tpu = args.tpu is not None

    device = 'CPU'
    global_batch_size = n_graphs   = config_tr['batch_size']   # need optimization
    physical_gpus = tf.config.experimental.list_physical_devices("GPU")
    n_gpus = len(physical_gpus)
    print("Found {} GPUs".format(n_gpus))
    n_tpus = 0
    n_cores_per_tpu = 8
    if use_tpu:
        if args.tpu == 'colab':
            resolver = tf.distribute.cluster_resolver.TPUClusterResolver()
        else:
            resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=args.tpu, zone=args.zone)
        workers = resolver.cluster_spec().as_dict()['worker']
        n_tpus = len(workers)
        print('Running on {} TPUs '.format(n_tpus), resolver.cluster_spec().as_dict()['worker'])
        tf.config.experimental_connect_to_cluster(resolver)
        tf.tpu.experimental.initialize_tpu_system(resolver)
        strategy = snt.distribute.TpuReplicator(resolver)
        device = 'TPU'
    elif n_gpus > 1:
        print("Useing SNT Replicator with {} GPUs".format(n_gpus))
        strategy = snt.distribute.Replicator(['/device:GPU:{}'.format(i) for i in range(n_gpus)],\
            tf.distribute.ReductionToOneDevice("CPU:0"))
        device = "{}GPUs".format(n_gpus)
        for dd in physical_gpus:
            tf.config.experimental.set_memory_growth(dd, True)
    elif n_gpus > 0:
        strategy = tf.distribute.OneDeviceStrategy("/device:GPU:0")
        device = "1GPU"
    else:
        strategy = tf.distribute.OneDeviceStrategy("/device:CPU:0")

    if n_gpus > 0:
        assert n_gpus == global_batch_size, "batch size {} does not equall to GPUs {}".format(global_batch_size, n_gpus)
    else:
        pass
        # assert global_batch_size == 1, "batch size {} does not equall to 1".format(global_batch_size)

    # add ops to save and restore all the variables
    prod_name = config['prod_name']
    if use_tpu:
        output_dir = os.path.join(config['tpu_output_dir'], prod_name)
    else:
        output_dir = os.path.join(config['output_dir'], prod_name)
        os.makedirs(output_dir, exist_ok=True)
    print("[{}] save models at {}".format(prog_name, output_dir))

    num_processing_steps_tr = config_tr['n_iters']      ## level of message-passing
    n_epochs = config_tr['epochs']
    print("{} epochs with batch size {}".format(n_epochs, global_batch_size))
    print("{} processing steps in the model".format(num_processing_steps_tr))
    # prepare graphs
    print("{} Eta bins and {} Phi bins".format(config['n_eta'], config['n_phi']))
    max_nodes, max_edges = graph.get_max_graph_size(config['n_eta'], config['n_phi'])

    if use_tpu:
        file_names = tf.io.gfile.glob(os.path.join(config['tfrec_dir_cloud'], config['tfrec_name']))
    else:
        file_names = tf.io.gfile.glob(os.path.join(config['tfrec_dir_local'], config['tfrec_name']))

    n_files = len(file_names)
    n_train = int(0.9*n_files)
    if n_train < 1: n_train = 1

    # print("Input file names: ", file_names)
    print("{} input files".format(n_files))
    print("{} training files".format(n_train))
    raw_dataset = tf.data.TFRecordDataset(file_names)
    training_dataset = raw_dataset.map(graph.parse_tfrec_function)

    AUTO = tf.data.experimental.AUTOTUNE
    options = tf.data.Options()
    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA
    training_dataset = training_dataset.with_options(options)
    training_dataset = training_dataset.batch(global_batch_size, drop_remainder=True).prefetch(AUTO)

    learning_rate = config_tr['learning_rate']
    with strategy.scope():
        optimizer = snt.optimizers.Adam(learning_rate)
        # model = SegmentClassifier()
        model = get_model(config['model_name'])


    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)
    ckpt_manager = tf.train.CheckpointManager(checkpoint, directory=output_dir, max_to_keep=5)
    print("Loading latest checkpoint from:", output_dir)
    status = checkpoint.restore(ckpt_manager.latest_checkpoint)

    # training loss
    if config_tr['real_weight']:
        real_weight = config_tr['real_weight']
        fake_weight = config_tr['fake_weight']
    else:
        real_weight = fake_weight = 1.0

    def log_loss(label, prediction, eps=1e-7, weights=1.):
        # tf.compat.v1.losses.log_loss, not supported by TPU
        # copy the TF source code here
        loss = tf.negative(tf.add(
            tf.multiply(label, tf.math.log(prediction+eps)),
            tf.multiply((1 - label), tf.math.log(1 - prediction+eps))))
        loss = tf.multiply(loss, weights)
        present = tf.where(
            tf.math.equal(weights, 0.0), tf.zeros_like(weights), tf.ones_like(weights))
        loss = tf.math.divide_no_nan(tf.math.reduce_sum(loss), tf.math.reduce_sum(present))
        return loss

    def create_loss_ops(target_op, output_ops):
        t_edges = tf.squeeze(target_op.edges)
        weights = t_edges * real_weight + (1 - t_edges) * fake_weight
        row_index = tf.range(tf.constant(max_edges))
        n_valid_edges = target_op.n_edge[0]
        
        # # NOTE: this implementation is very low
        # # cond = (row_index < n_valid_edges)
        # # zeros = tf.zeros_like(weights, dtype=weights.dtype)
        # # weights = tf.where(cond, weights, zeros)

        mask = tf.cast(row_index < n_valid_edges, tf.float32)
        # mask = tf.expand_dims(mask, axis=1)
        weights = weights * mask

        loss_ops = [
            tf.compat.v1.losses.log_loss(t_edges, tf.squeeze(output_op.edges), weights=weights)
                for output_op in output_ops
        ]

        return tf.stack(loss_ops)

    # @tf.function(autograph=False)
    # @tf.function(experimental_compile=True) # enable XLA compilation, may speedup the training!
    @tf.function(experimental_compile=True)
    def train_step(inputs_tr, targets_tr):
        print("Tracing train_step")
        print(inputs_tr)

        def update_step(inputs_tr, targets_tr):
            print("Tracing update_step")
            print("before contatenate:", inputs_tr.n_node.shape)
            inputs_tr = graph.concat_batch_dim(inputs_tr)
            targets_tr = graph.concat_batch_dim(targets_tr)
            print("after concatenate:", inputs_tr.n_node.shape)

            with tf.GradientTape() as tape:
                outputs_tr = model(inputs_tr, num_processing_steps_tr)
                loss_ops_tr = create_loss_ops(targets_tr, outputs_tr)
                loss_op_tr = tf.math.reduce_sum(loss_ops_tr) / tf.constant(num_processing_steps_tr, dtype=tf.float32)

            gradients = tape.gradient(loss_op_tr, model.trainable_variables)
            # aggregate the gradients from the full batch.
            # this is not there for mirror strategy
            replica_ctx = tf.distribute.get_replica_context()
            gradients = replica_ctx.all_reduce("mean", gradients)

            optimizer.apply(gradients, model.trainable_variables)
            return loss_op_tr

        per_example_losses = strategy.run(update_step, args=(inputs_tr,targets_tr))
        mean_loss = strategy.reduce("sum", per_example_losses, axis=None)
        return mean_loss

    def train_epoch(dataset):
        total_loss = 0.
        num_batches = 0
        for inputs in dataset:
            input_tr, target_tr = inputs
            total_loss += train_step(input_tr, target_tr)
            num_batches += 1
        print("total batches:", num_batches)
        return total_loss/num_batches

    out_str  = "Start training " + time.strftime('%d %b %Y %H:%M:%S', time.localtime())
    out_str += '\n'
    out_str += "Epoch, Time [mins], Loss\n"
    log_name = os.path.join("training_log.txt")
    with open(log_name, 'a') as f:
        f.write(out_str)
    now = time.time()

    dist_training_dataset = strategy.experimental_distribute_dataset(training_dataset)
    for epoch in range(n_epochs):
        print("start epoch {} on {}".format(epoch, device))
        # if not use_tpu:
        #     training_dataset = training_dataset.shuffle(global_batch_size*2, reshuffle_each_iteration=True)

        loss = train_epoch(dist_training_dataset)
        # loss = train_epoch(training_dataset)
        this_epoch = time.time()
        
        print("Training {} epoch, {:.2f} mins, Loss := {:.4f}".format(
            epoch, (this_epoch-now)/60., loss/global_batch_size))
        out_str = "{}, {:.2f}, {:.4f}\n".format(epoch, (this_epoch-now)/60., loss/global_batch_size)
        with open(log_name, 'a') as f:
            f.write(out_str)

        now = this_epoch
        ckpt_manager.save()

    out_log = "End @ " + time.strftime('%d %b %Y %H:%M:%S', time.localtime()) + "\n"
    with open(log_name, 'a') as f:
        f.write(out_log)