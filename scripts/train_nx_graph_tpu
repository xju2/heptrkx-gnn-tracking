#!/usr/bin/env python
"""
Training GNN in TPU/GPU/CPU with fixed graph size
Its input is TFRecord
"""

import tensorflow as tf
print(tf.__version__)

import os
import sys
import argparse
import glob
import re
import time
import random
import functools

import numpy as np
import sklearn.metrics


from graph_nets import utils_tf
from graph_nets import utils_np
import sonnet as snt

from heptrkx.dataset import graph
from heptrkx.nx_graph import get_model
from heptrkx.utils import load_yaml

prog_name = os.path.basename(sys.argv[0])

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Train nx-graph with configurations')
    add_arg = parser.add_argument
    add_arg('config', help='configuration file')
    add_arg('--tpu', help='use tpu', default=None)
    args = parser.parse_args()

    print(args.config)
    all_config = load_yaml(args.config)
    config = all_config['gnn_training']
    config_tr = config['parameters']
    use_tpu = args.tpu is not None

    global_batch_size = n_graphs   = config_tr['batch_size']   # need optimization
    physical_gpus = tf.config.experimental.list_physical_devices("GPU")
    n_gpus = len(physical_gpus)
    if n_gpus > 0:
        assert n_gpus == global_batch_size, "batch size {} does not equall to GPUs {}".format(global_batch_size, n_gpus)
    else:
        pass
        # assert global_batch_size == 1, "batch size {} does not equall to 1".format(global_batch_size)

    device = 'CPU'
    if use_tpu:
        if args.tpu == 'colab':
            resolver = tf.distribute.cluster_resolver.TPUClusterResolver()
        else:
            resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=args.tpu)
        print('Running on TPU ', resolver.cluster_spec().as_dict()['worker'])
        tf.config.experimental_connect_to_cluster(resolver)
        tf.tpu.experimental.initialize_tpu_system(resolver)
        strategy = snt.distribute.TpuReplicator(resolver)
        device = 'TPU'
    elif n_gpus > 1:
        print("Useing SNT Replicator with {} GPUs".format(n_gpus))
        strategy = snt.distribute.Replicator(['/device:GPU:{}'.format(i) for i in range(n_gpus)],\
            tf.distribute.ReductionToOneDevice("GPU:0"))
        device = "{}GPUs".format(n_gpus)
    elif n_gpus > 0:
        strategy = tf.distribute.OneDeviceStrategy("/device:GPU:0")
        device = "1GPU"
    else:
        strategy = tf.distribute.OneDeviceStrategy("/device:CPU:0")

    # add ops to save and restore all the variables
    prod_name = config['prod_name']
    if use_tpu:
        output_dir = os.path.join(config['tpu_output_dir'], prod_name)
    else:
        output_dir = os.path.join(config['output_dir'], prod_name)
        os.makedirs(output_dir, exist_ok=True)
    print("[{}] save models at {}".format(prog_name, output_dir))
    num_processing_steps_tr = config_tr['n_iters']      ## level of message-passing
    n_epochs = config_tr['epochs']
    print("{} epochs".format(n_epochs))
    print("{} processing steps in the model".format(num_processing_steps_tr))
    # prepare graphs
    print("Node features: ", config['node_features'])
    print("Edge features: ", config['edge_features'])
    print("{} Eta bins and {} Phi bins".format(config['n_eta'], config['n_phi']))
    max_nodes, max_edges = graph.get_max_graph_size(config['n_eta'], config['n_phi'])

    if use_tpu:
        file_names = tf.io.gfile.glob(os.path.join(config['tfrec_dir_cloud'], config['tfrec_name']))
    else:
        file_names = tf.io.gfile.glob(os.path.join(config['tfrec_dir_local'], config['tfrec_name']))

    print("Input file names: ", file_names)
    raw_dataset = tf.data.TFRecordDataset(file_names)
    training_dataset = raw_dataset.map(graph.parse_tfrec_function)

    AUTO = tf.data.experimental.AUTOTUNE
    # training_dataset = training_dataset.repeat().shuffle(2048).batch(global_batch_size).prefetch(AUTO)
    training_dataset = training_dataset.batch(global_batch_size).prefetch(AUTO)

    learning_rate = config_tr['learning_rate']
    with strategy.scope():
        optimizer = snt.optimizers.Adam(learning_rate)
        model = get_model(config['model_name'])

    # output_dir = 'gs://gnn-v1/model'
    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)
    ckpt_manager = tf.train.CheckpointManager(checkpoint, directory=output_dir, max_to_keep=5)
    print("Loading latest checkpoint")
    status = checkpoint.restore(ckpt_manager.latest_checkpoint)

    # training loss
    if config_tr['real_weight']:
        real_weight = config_tr['real_weight']
        fake_weight = config_tr['fake_weight']
    else:
        real_weight = fake_weight = 1.0

    def log_loss(label, prediction, eps=1e-7, weights=1.):
        # tf.compat.v1.losses.log_loss, not supported by TPU
        # copy the TF source code here
        loss = tf.negative(tf.add(
            tf.multiply(label, tf.math.log(prediction+eps)),
            tf.multiply((1 - label), tf.math.log(1 - prediction+eps))))
        loss = tf.multiply(loss, weights)
        present = tf.where(
            tf.math.equal(weights, 0.0), tf.zeros_like(weights), tf.ones_like(weights))
        loss = tf.math.divide_no_nan(tf.math.reduce_sum(loss), tf.math.reduce_sum(present))
        return loss

    def create_loss_ops(target_op, output_ops):
        weights = target_op.edges * real_weight + (1 - target_op.edges) * fake_weight
        row_index = tf.range(tf.constant(max_edges))
        n_valid_edges = target_op.n_edge[0]
        
        # NOTE: this implementation is very low
        # cond = (row_index < n_valid_edges)
        # zeros = tf.zeros_like(weights, dtype=weights.dtype)
        # weights = tf.where(cond, weights, zeros)

        mask = tf.cast(row_index < n_valid_edges, tf.float32)
        mask = tf.expand_dims(mask, axis=1)
        weights = weights * mask
        loss_ops = [
            log_loss(target_op.edges, output_op.edges, weights=weights)
                for output_op in output_ops
        ]
        return tf.stack(loss_ops)

    @tf.function
    def train_step(inputs_tr, targets_tr):
        print("Tracing train_step")
        print(inputs_tr)
        
        def update_step(inputs_tr, targets_tr):
            print("Tracing update_step")
            print("before contatenate:", inputs_tr.nodes.shape)
            inputs_tr = graph.concat_batch_dim(inputs_tr)
            targets_tr = graph.concat_batch_dim(targets_tr)
            print("after concatenate:", inputs_tr.nodes.shape)

            with tf.GradientTape() as tape:
                outputs_tr = model(inputs_tr, num_processing_steps_tr)
                loss_ops_tr = create_loss_ops(targets_tr, outputs_tr)
                loss_op_tr = tf.math.reduce_sum(loss_ops_tr) / tf.constant(num_processing_steps_tr, dtype=tf.float32)

            gradients = tape.gradient(loss_op_tr, model.trainable_variables)
            # aggregate the gradients from the full batch.
            # this is not there for mirror strategy
            replica_ctx = tf.distribute.get_replica_context()
            gradients = replica_ctx.all_reduce("mean", gradients)

            optimizer.apply(gradients, model.trainable_variables)
            return loss_op_tr

        per_example_losses = strategy.run(update_step, args=(inputs_tr,targets_tr))
        mean_loss = strategy.reduce("sum", per_example_losses, axis=None)
        return mean_loss

    def train_epoch(dataset):
        total_loss = 0.
        num_batches = 0
        for inputs in dataset:
            input_tr, target_tr = inputs
            total_loss += train_step(input_tr, target_tr)
            num_batches += 1
        return total_loss/num_batches

    now = time.time()
    for epoch in range(n_epochs):
        print("start epoch {} on {}".format(epoch, device))
        training_dataset = training_dataset.shuffle(global_batch_size*2, reshuffle_each_iteration=True)
        if "CPU" in device or "GPU" in device:
            dist_training_dataset = strategy.experimental_distribute_dataset(training_dataset)
            loss = train_epoch(dist_training_dataset)
        else:
            # dist_training_dataset = strategy.experimental_distribute_dataset(training_dataset)
            # loss = train_epoch(dist_training_dataset)
            loss = train_epoch(training_dataset)
        this_epoch = time.time()
        print("Training {} epoch, {:.2f} mins, Loss := {:.4f}".format(epoch, (this_epoch-now)/60., loss/global_batch_size))
        now = this_epoch
        ckpt_manager.save()