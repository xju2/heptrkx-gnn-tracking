#!/usr/bin/env python
"""
Training GNN on GPU/CPU with dynamic graph size
Its input is generated from a python generator
"""

import tensorflow as tf
print(tf.__version__)

import os
import sys
import argparse
import glob
import re
import time
import random
import functools

import numpy as np
import sklearn.metrics


from graph_nets import utils_tf
from graph_nets import utils_np
import sonnet as snt

from heptrkx.dataset import graph
from heptrkx.nx_graph import get_model
from heptrkx.utils import load_yaml

# ckpt_name = 'checkpoint_{:05d}.ckpt'
ckpt_name = 'checkpoint'

prog_name = os.path.basename(sys.argv[0])

def eval_output(target, output):
    """
    target, output are graph-tuple from TF-GNN,
    each of them contains N=batch-size graphs
    """
    tdds = utils_np.graphs_tuple_to_data_dicts(target)
    odds = utils_np.graphs_tuple_to_data_dicts(output)

    test_target = []
    test_pred = []
    for td, od in zip(tdds, odds):
        test_target.append(np.squeeze(td['edges']))
        test_pred.append(np.squeeze(od['edges']))

    test_target = np.concatenate(test_target, axis=0)
    test_pred   = np.concatenate(test_pred,   axis=0)
    return test_pred, test_target


def compute_matrics(target, output, thresh=0.5):
    test_pred, test_target = eval_output(target, output)
    y_pred, y_true = (test_pred > thresh), (test_target > thresh)
    return sklearn.metrics.precision_score(y_true, y_pred), sklearn.metrics.recall_score(y_true, y_pred)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Train nx-graph with configurations')
    add_arg = parser.add_argument
    add_arg('config', help='configuration file')
    add_arg('--tpu', help='use tpu', default=None)
    args = parser.parse_args()

    print(args.config)
    all_config = load_yaml(args.config)
    config = all_config['gnn_training']


    # add ops to save and restore all the variables
    prod_name = config['prod_name']
    output_dir = os.path.join(config['output_dir'], prod_name)
    print("[{}] save models at {}".format(prog_name, output_dir))
    os.makedirs(output_dir, exist_ok=True)

    config_tr = config['parameters']
    log_every_seconds       = config_tr['time_lapse']
    global_batch_size = n_graphs   = config_tr['batch_size']   # need optimization
    num_training_iterations = config_tr['iterations']
    iter_per_job            = 2500 if 'iter_per_job' not in config_tr else config_tr['iter_per_job']
    num_processing_steps_tr = config_tr['n_iters']      ## level of message-passing
    print("Maximum iterations per job: {}".format(iter_per_job))

    # model and optimizers
    learning_rate = config_tr['learning_rate']
    physical_gpus = tf.config.experimental.list_physical_devices("GPU")
    physical_cpus = tf.config.experimental.list_physical_devices("CPU")
    physical_tpus = tf.config.experimental.list_physical_devices("TPU")
    print("{} CPUs, {} GPUs and {} TPUs".format(
        len(physical_cpus), len(physical_gpus), len(physical_tpus)))
    n_gpus = len(physical_gpus)
    with_batch_dim = False
    with_pad = True
    if args.tpu is not None:
        if args.tpu == 'colab':
            resolver = tf.distribute.cluster_resolver.TPUClusterResolver()
        else:
            resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=args.tpu)
        print('Running on TPU ', resolver.cluster_spec().as_dict()['worker'])
        tf.config.experimental_connect_to_cluster(resolver)
        tf.tpu.experimental.initialize_tpu_system(resolver)
        strategy = tf.distribute.experimental.TPUStrategy(resolver)
    elif n_gpus > 1:
        print("Useing SNT Replicator with {} GPUs".format(n_gpus))
        assert n_gpus == global_batch_size, "batch size {} does not equall to GPUs {}".format(global_batch_size, n_gpus)
        strategy = snt.distribute.Replicator(['/device:GPU:{}'.format(i) for i in range(n_gpus)],\
            tf.distribute.ReductionToOneDevice("GPU:0"))
    elif n_gpus > 0:
        strategy = tf.distribute.OneDeviceStrategy("/device:GPU:0")
    else:
        strategy = tf.distribute.OneDeviceStrategy("/device:CPU:0")

    with strategy.scope():
        optimizer = snt.optimizers.Adam(learning_rate)
        model = get_model(config['model_name'])
    # prepare graphs
    print("Node features: ", config['node_features'])
    print("Edge features: ", config['edge_features'])
    # doublet_graphs = graph.DoubletGraphGenerator(
    #     config['n_eta'], config['n_phi'],
    #     config['node_features'], config['edge_features'], 
    #     with_batch_dim=with_batch_dim,
    #     with_pad=with_pad
    #     )
    # for hit_file, doublet_file in zip(config['hit_files'], config['doublet_files']):
    #     doublet_graphs.add_file(hit_file, doublet_file)

    n_epochs = config_tr['epochs']
    # buffer_size = global_batch_size*2
    # training_dataset = doublet_graphs.create_dataset(is_training=True)
    # training_dataset = training_dataset.repeat().shuffle(2048).batch(global_batch_size).prefetch(tf.data.experimental.AUTOTUNE)
    # training_dataset = training_dataset.prefetch(tf.data.experimental.AUTOTUNE)
    # training_dataset = training_dataset.repeat(n_epochs)
    # training_dataset = training_dataset.shuffle(buffer_size)
    # training_dataset = training_dataset.cache('./tf.dataset.cache.{}epochs'.format(n_epochs))
    # training_dataset = training_dataset.cache()
    # training_dataset = training_dataset.batch(global_batch_size)

    file_names = tf.io.gfile.glob(os.path.join(config['tfrec_dir_local'], config['tfrec_name']))
    print("Input file names: ", file_names)
    raw_dataset = tf.data.TFRecordDataset(file_names)
    training_dataset = raw_dataset.map(graph.parse_tfrec_function)

    AUTO = tf.data.experimental.AUTOTUNE
    # training_dataset = training_dataset.repeat().shuffle(2048).batch(global_batch_size).prefetch(AUTO)
    training_dataset = training_dataset.batch(global_batch_size).prefetch(AUTO)


    # testing_dataset = doublet_graphs.create_dataset(is_training=False)


    # training loss
    if config_tr['real_weight']:
        real_weight = config_tr['real_weight']
        fake_weight = config_tr['fake_weight']
    else:
        real_weight = fake_weight = 1.0

    def __create_loss_ops(target_op, output_ops):
        loss_ops = []
        for output_op in output_ops:
            num_graphs = utils_tf.get_num_graphs(output_op)
            if with_pad:
                num_graphs -= 1
            for igraph in range(num_graphs):
                target_slice = utils_tf.get_graph(target_op, igraph)
                output_slice = utils_tf.get_graph(output_op, igraph)
                weights = target_slice.edges * real_weight + (1 - target_slice.edges) * fake_weight
                local_loss = tf.compat.v1.losses.log_loss(
                    target_slice.edges,
                    output_slice.edges,
                    weights=weights
                )
                tf.print(tf.shape(local_loss))
                loss_ops.append(local_loss)

        return tf.stack(loss_ops)

    def create_loss_ops(target_op, output_ops):
        weights = target_op.edges * real_weight + (1 - target_op.edges) * fake_weight
        row_index = tf.range(tf.math.reduce_sum(target_op.n_edge))
        n_valid_edges = target_op.n_edge[0]
        mask = tf.cast(row_index < n_valid_edges, tf.float32)
        mask = tf.expand_dims(mask, axis=1)
        weights = weights * mask
        loss_ops = [
            tf.compat.v1.losses.log_loss(target_op.edges, output_op.edges, weights=weights)
            for output_op in output_ops
        ]
        return tf.stack(loss_ops)

    @tf.function
    def train_step(inputs_tr, targets_tr):
        print("Tracing train_step")
        
        def update_step(inputs_tr, targets_tr):
            print("Tracing update_step")
            inputs_tr = graph.concat_batch_dim(inputs_tr)
            targets_tr = graph.concat_batch_dim(targets_tr)
            with tf.GradientTape() as tape:
                outputs_tr = model(inputs_tr, num_processing_steps_tr)
                loss_ops_tr = create_loss_ops(targets_tr, outputs_tr)
                loss_op_tr = tf.math.reduce_sum(loss_ops_tr) / tf.constant(num_processing_steps_tr, dtype=tf.float32)

            gradients = tape.gradient(loss_op_tr, model.trainable_variables)
            # aggregate the gradients from the full batch.
            # this is not there for mirror strategy
            replica_ctx = tf.distribute.get_replica_context()
            gradients = replica_ctx.all_reduce("mean", gradients)

            optimizer.apply(gradients, model.trainable_variables)
            return loss_op_tr

        per_example_losses = strategy.run(update_step, args=(inputs_tr,targets_tr))
        mean_loss = strategy.reduce("sum", per_example_losses, axis=None)
        return mean_loss

    def train_epoch(dataset):
        total_loss = 0.
        num_batches = 0
        for inputs in dataset:
            # print("Step {}".format(num_batches))
            input_tr, target_tr = inputs
            # print(target_tr)
            total_loss += train_step(input_tr, target_tr).numpy()
            num_batches += 1
        return total_loss/num_batches

    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)
    ckpt_manager = tf.train.CheckpointManager(checkpoint, directory=output_dir, max_to_keep=5)
    # if os.path.exists(os.path.join(output_dir, ckpt_name)):
    print("Loading latest checkpoint")
    status = checkpoint.restore(ckpt_manager.latest_checkpoint)

    now = time.time()
    for epoch in range(n_epochs):
        print("Training epoch", epoch, "...", end=' ')
        training_dataset = training_dataset.shuffle(global_batch_size*2, reshuffle_each_iteration=True)
        # distributed dataset
        dist_training_dataset = strategy.experimental_distribute_dataset(training_dataset)
        loss = train_epoch(dist_training_dataset)
        this_epoch = time.time()
        print("{:.2f} mins, Loss := {}".format((this_epoch-now)/60., loss/global_batch_size))
        now = this_epoch
        ckpt_manager.save()