#!/usr/bin/env python 
"""
Select doublets for making graph from the pre-doublet candidates
"""
import os
import argparse
import numpy as np
import pandas as pd

from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow import keras


from heptrkx.utils import load_yaml
from heptrkx.nx_graph import shadow_model
from heptrkx.utils import layer_pairs
from heptrkx import master

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='select doublets using trained neural networks')
    add_arg = parser.add_argument
    add_arg('input_file', help='input pre-doublets')
    add_arg('config_file', help='configuration file')
    add_arg('outname', help='output doublets')

    args = parser.parse_args()

    input_file = args.input_file
    config_file = args.config_file
    outname = args.outname

    config = load_yaml(config_file)

    # NN configurations
    train_cfg = config['doublet_training']
    features = train_cfg['features']
    model_weight_base_dir = os.path.expandvars(train_cfg['model_output_dir'])
    model_name = train_cfg['model']

    # NN thresholds
    cuts = config['segments_from_NN']['cuts']

    # input dataset
    input_dir = config['track_ml']['dir']
    event = master.Event(input_dir)
    scaler = StandardScaler()

    with pd.HDFStore(outname, mode='w') as store:
        # read pre-doublets
        with pd.HDFStore(input_file, mode='r') as doublets:
            all_keys = list(doublets.keys())
            evtid_list = np.unique([int(x.split('/')[1][3:]) for x in all_keys]).tolist()
            pair_list = np.unique([int(x.split('/')[2][4:]) for x in all_keys]).tolist()

            segments_dict = {}
            for evtid in evtid_list:
                for pairid in pair_list:
                    cut = cuts[pairid]
                    layer_pair = layer_pairs[pairid]
                    # Load the NN model for that layer pair
                    model_weight_dir = os.path.join(model_weight_base_dir, 'pair{:03d}'.format(pairid), 'modelpair{:03}.ckpt'.format(pairid))
                    with tf.compat.v1.Session(graph=tf.Graph()) as sess:
                        # model = getattr(shadow_model, model_name)()
                        # model.load_weights(model_weight_dir)
                        model = keras.models.load_model(model_weight_dir)

                        key = 'evt{}/pair{}'.format(evtid, pairid)
                        doublet = doublets[key]
                        all_inputs = scaler.fit_transform(doublet[features].values)
                        prediction = model.predict(all_inputs)
                        passed_segments = doublet[prediction > cut]
                        store[key] = passed_segments