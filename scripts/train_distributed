#!/usr/bin/env python
"""
Training GNN on GPU/CPU with dynamic graph size
Its input is generated from a python generator
"""

import tensorflow as tf
print(tf.__version__)

import os
import sys
import argparse
import glob
import re
import time
import random
import functools

import numpy as np
import sklearn.metrics


from graph_nets import utils_tf
from graph_nets import utils_np
import sonnet as snt

from heptrkx.dataset import graph
from heptrkx.nx_graph import distribute_model
from heptrkx.utils import load_yaml

# ckpt_name = 'checkpoint_{:05d}.ckpt'
ckpt_name = 'checkpoint'

prog_name = os.path.basename(sys.argv[0])

def eval_output(target, output):
    """
    target, output are graph-tuple from TF-GNN,
    each of them contains N=batch-size graphs
    """
    tdds = utils_np.graphs_tuple_to_data_dicts(target)
    odds = utils_np.graphs_tuple_to_data_dicts(output)

    test_target = []
    test_pred = []
    for td, od in zip(tdds, odds):
        test_target.append(np.squeeze(td['edges']))
        test_pred.append(np.squeeze(od['edges']))

    test_target = np.concatenate(test_target, axis=0)
    test_pred   = np.concatenate(test_pred,   axis=0)
    return test_pred, test_target


def compute_matrics(target, output, thresh=0.5):
    test_pred, test_target = eval_output(target, output)
    y_pred, y_true = (test_pred > thresh), (test_target > thresh)
    return sklearn.metrics.precision_score(y_true, y_pred), sklearn.metrics.recall_score(y_true, y_pred)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Train nx-graph with configurations')
    add_arg = parser.add_argument
    add_arg('config', help='configuration file')
    add_arg('--tpu', help='use tpu', default=None)
    args = parser.parse_args()

    print(args.config)
    all_config = load_yaml(args.config)
    config = all_config['gnn_training']
    use_tpu = args.tpu is not None


    # add ops to save and restore all the variables
    prod_name = config['prod_name']
    if use_tpu:
        output_dir = os.path.join(config['tpu_output_dir'], prod_name)
    else:
        output_dir = os.path.join(config['output_dir'], prod_name)
        os.makedirs(output_dir, exist_ok=True)
    print("[{}] save models at {}".format(prog_name, output_dir))

    config_tr = config['parameters']
    global_batch_size = n_graphs   = config_tr['batch_size']   # need optimization
    num_processing_steps_tr = config_tr['n_iters']      ## level of message-passing

    # model and optimizers
    learning_rate = config_tr['learning_rate']
    physical_gpus = tf.config.experimental.list_physical_devices("GPU")
    physical_cpus = tf.config.experimental.list_physical_devices("CPU")
    physical_tpus = tf.config.experimental.list_physical_devices("TPU")
    print("{} CPUs, {} GPUs and {} TPUs".format(
        len(physical_cpus), len(physical_gpus), len(physical_tpus)))
    n_gpus = len(physical_gpus)
    with_batch_dim = False
    with_pad = True
    if args.tpu is not None:
        if args.tpu == 'colab':
            resolver = tf.distribute.cluster_resolver.TPUClusterResolver()
        else:
            resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=args.tpu)
        workers = resolver.cluster_spec().as_dict()['worker']
        n_tpus = len(workers)
        print('Running on {} TPUs '.format(n_tpus), resolver.cluster_spec().as_dict()['worker'])
        tf.config.experimental_connect_to_cluster(resolver)
        tf.tpu.experimental.initialize_tpu_system(resolver)
        strategy = snt.distribute.TpuReplicator(resolver)
        device = 'TPU'
    elif n_gpus > 1:
        print("Useing SNT Replicator with {} GPUs".format(n_gpus))
        assert n_gpus == global_batch_size, "batch size {} does not equall to GPUs {}".format(global_batch_size, n_gpus)
        strategy = snt.distribute.Replicator(['/device:GPU:{}'.format(i) for i in range(n_gpus)],\
            tf.distribute.ReductionToOneDevice("GPU:0"))
        device = "{}GPUs".format(n_gpus)
    elif n_gpus > 0:
        strategy = tf.distribute.OneDeviceStrategy("/device:GPU:0")
        device = "1GPU"
    else:
        strategy = tf.distribute.OneDeviceStrategy("/device:CPU:0")

    with strategy.scope():
        optimizer = snt.optimizers.Adam(learning_rate)
        model = distribute_model.SegmentClassifier()

    n_epochs = config_tr['epochs']

    if use_tpu:
        file_names = tf.io.gfile.glob(os.path.join(config['tfrec_dir_cloud'], config['tfrec_name']))
    else:
        file_names = tf.io.gfile.glob(os.path.join(config['tfrec_dir_local'], config['tfrec_name']))
    print("Input file names: ", file_names)
    raw_dataset = tf.data.TFRecordDataset(file_names)
    training_dataset = raw_dataset.map(graph.parse_tfrec_function)

    AUTO = tf.data.experimental.AUTOTUNE
    training_dataset = training_dataset.batch(global_batch_size).prefetch(AUTO)

    # training loss
    if config_tr['real_weight']:
        real_weight = config_tr['real_weight']
        fake_weight = config_tr['fake_weight']
    else:
        real_weight = fake_weight = 1.0


    def create_loss_ops(target_op, output_ops):
        weights = target_op.edges * real_weight + (1 - target_op.edges) * fake_weight
        row_index = tf.range(tf.math.reduce_sum(target_op.n_edge))
        n_valid_edges = target_op.n_edge[0]
        mask = tf.cast(row_index < n_valid_edges, tf.float32)
        mask = tf.expand_dims(mask, axis=1)
        weights = weights * mask
        loss_ops = [
            tf.compat.v1.losses.log_loss(target_op.edges, output_op.edges, weights=weights)
            for output_op in output_ops
        ]
        return tf.stack(loss_ops)

    @tf.function
    def train_step(inputs_tr, targets_tr):
        print("Tracing train_step")
        
        def update_step(inputs_tr, targets_tr):
            print("Tracing update_step")
            inputs_tr = graph.concat_batch_dim(inputs_tr)
            targets_tr = graph.concat_batch_dim(targets_tr)
            with tf.GradientTape() as tape:
                outputs_tr = model(inputs_tr, num_processing_steps_tr)
                loss_ops_tr = create_loss_ops(targets_tr, outputs_tr)
                loss_op_tr = tf.math.reduce_sum(loss_ops_tr) / tf.constant(num_processing_steps_tr, dtype=tf.float32)

            gradients = tape.gradient(loss_op_tr, model.trainable_variables)
            # aggregate the gradients from the full batch.
            # this is not there for mirror strategy
            replica_ctx = tf.distribute.get_replica_context()
            gradients = replica_ctx.all_reduce("mean", gradients)

            optimizer.apply(gradients, model.trainable_variables)
            return loss_op_tr

        per_example_losses = strategy.run(update_step, args=(inputs_tr,targets_tr))
        mean_loss = strategy.reduce("sum", per_example_losses, axis=None)
        return mean_loss

    def train_epoch(dataset):
        total_loss = 0.
        num_batches = 0
        for inputs in dataset:
            # print("Step {}".format(num_batches))
            input_tr, target_tr = inputs
            # print(target_tr)
            total_loss += train_step(input_tr, target_tr).numpy()
            num_batches += 1
        return total_loss/num_batches

    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)
    ckpt_manager = tf.train.CheckpointManager(checkpoint, directory=output_dir, max_to_keep=5)
    # if os.path.exists(os.path.join(output_dir, ckpt_name)):
    print("Loading latest checkpoint from:", output_dir)
    status = checkpoint.restore(ckpt_manager.latest_checkpoint)

    now = time.time()
    for epoch in range(n_epochs):
        print("Training epoch", epoch, "...", end=' ')
        training_dataset = training_dataset.shuffle(global_batch_size*2, reshuffle_each_iteration=True)
        # distributed dataset
        dist_training_dataset = strategy.experimental_distribute_dataset(training_dataset)
        loss = train_epoch(dist_training_dataset)
        this_epoch = time.time()
        print("Training {} epoch, {:.2f} mins, Loss := {:.4f}".format(epoch, (this_epoch-now)/60., loss/global_batch_size))
        now = this_epoch
        ckpt_manager.save()