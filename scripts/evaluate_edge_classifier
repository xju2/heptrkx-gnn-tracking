#!/usr/bin/env python

import os

import tensorflow as tf
import sonnet as snt

import pickle
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import networkx as nx

from graph_nets import utils_tf

from heptrkx.dataset import graph
from heptrkx.nx_graph import get_model
from heptrkx.nx_graph import distribute_model
from heptrkx.utils import load_yaml
from heptrkx.utils_plot import plot_metrics
from heptrkx import utils
from heptrkx import utils_plot
from heptrkx.dataset import event as master

ckpt_name = 'checkpoint'

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Evaluate trained GNN model")
    add_arg = parser.add_argument
    add_arg("config", help='training configuration')
    add_arg("input_data", help='input tfrec data')
    add_arg("tf_index", help='the index in the tfrec data', type=int)
    add_arg("outdir", help='output directory')
    add_arg('--model-dir', help='model directory', default=None)
    add_arg('--nevts', help='number of events', default=1, type=int)
    add_arg('--inspect', help='inspect intermediate results', action='store_true')
    add_arg("--input-dir", help='dataset input directory', \
        default='/global/homes/x/xju/m3443/data/trackml-kaggle/train_all')
    add_arg("--edge-distributed", help='edge distributed model', action='store_true')
    add_arg("--remove-padding", help="remove pad graph from evaluation", action='store_true')
    args = parser.parse_args()

    filenames = tf.io.gfile.glob(args.input_data)
    tf_index = args.tf_index
    nevts = args.nevts
    print("Input file names:", filenames)
    print("In total", len(filenames), "files")
    print("Process", nevts, "events")
    if not "gs://" in args.outdir:
        os.makedirs(args.outdir, exist_ok=True)

    # load data
    raw_dataset = tf.data.TFRecordDataset(filenames)
    dataset = raw_dataset.map(graph.parse_tfrec_function)
    AUTO = tf.data.experimental.AUTOTUNE
    dataset = dataset.prefetch(AUTO)

    with_batch_dim = False
    inputs, targets = next(dataset.take(1).as_numpy_iterator())
    input_signature = (
        graph.specs_from_graphs_tuple(inputs, with_batch_dim),
        graph.specs_from_graphs_tuple(targets, with_batch_dim)
    )

    # load model
    all_config = load_yaml(args.config)
    config = all_config['gnn_training']
    config_tr = config['parameters']

    num_processing_steps_tr = config_tr['n_iters']      ## level of message-passing
    learning_rate = config_tr['learning_rate']
    optimizer = snt.optimizers.Adam(learning_rate)
    if args.edge_distributed:
        model = distribute_model.SegmentClassifier()
    else:
        model = get_model(config['model_name'])

    # where to find the model
    prod_name = config['prod_name']
    output_dir = os.path.join(config['output_dir'], prod_name)
    if args.model_dir is not None:
        output_dir = args.model_dir

    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)
    ckpt_manager = tf.train.CheckpointManager(checkpoint, directory=output_dir, max_to_keep=5)
    if os.path.exists(os.path.join(output_dir, ckpt_name)):
        print("Find model:", output_dir)
        print("Loading latest checkpoint from:", output_dir)
        status = checkpoint.restore(ckpt_manager.latest_checkpoint)
    else:
        raise ValueError("cannot find model at:", output_dir)

    # NOTE: prepare to get ID info for the doublets, all hard-coded. <xju>
    evt_filename = '/global/homes/x/xju/atlas/heptrkx/codalab/embeded_doublets.pkl'
    with open(evt_filename, 'rb') as f:
        pickler = pickle.Unpickler(f)
        all_evtids = pickler.load()
    try:
        evtids = all_evtids[tf_index]
    except IndexError:
        print("available event IDs:", all_evtids)
        exit(1)

    origin_doublets_input = '/project/projectdirs/m3443/usr/dtmurnane/doublets/high_fullsplit'
    id_basename = os.path.join(origin_doublets_input, 'event{}_{}_ID.npz')
    nsections = 8

    outputs_te_list = []
    targets_te_list = []
    ievt = 0

    if args.inspect:
        event = master.Event(args.input_dir)

    for inputs in dataset.take(nevts).as_numpy_iterator():
        inputs_te, targets_te = inputs
        outputs_te = model(inputs_te, num_processing_steps_tr)
        
        if len(targets_te.n_edge) > 1 and args.remove_padding:
            pad_idx = targets_te.n_edge[0]
            output_graph = outputs_te[-1].replace(edges=outputs_te[-1].edges[:pad_idx, ])
            target_graph = targets_te.replace(edges=targets_te.edges[:pad_idx, ])
        else:
            output_graph = outputs_te[-1]
            target_graph = targets_te

        outputs_te_list.append(output_graph)
        targets_te_list.append(target_graph)

        evtid = evtids[ievt]

        # each event has 8 sections
        hits_id_nsecs = []
        hits_pid_nsecs = []
        for isec in range(nsections):
            id_filename = id_basename.format(evtid, isec)
            if not os.path.exists(id_filename):
                raise ValueError("cannot find", id_filename)
            else:
                array = np.load(id_filename)
                hits_id_nsecs.append(array['I'])
                hits_pid_nsecs.append(array['pid'])

        hits_id_nsecs = np.unique(np.concatenate(hits_id_nsecs))
        hits_pid_nsecs = np.unique(np.concatenate(hits_pid_nsecs))

        output = os.path.join(args.outdir, "event{}.npz".format(evtid))
        np.savez(
            output,
            receivers=inputs_te.receivers,
            senders=inputs_te.senders,
            score=tf.reshape(outputs_te[-1].edges, (-1, )),
            truth=tf.reshape(targets_te.edges, (-1, )),
            I=hits_id_nsecs,
            pid=hits_pid_nsecs
            )
        if args.inspect:
            array = {}
            array['I'] = hits_id_nsecs
            array['receivers'] = inputs_te.receivers
            array['senders'] = inputs_te.senders
            array['truth'] = tf.reshape(targets_te.edges, (-1, ))
            event.read(evtid) 
            y_test = array['truth']
            for i in range(num_processing_steps_tr):
                array['score'] = tf.reshape(outputs_te[i].edges, (-1, )).numpy()
                score =  array['score']
                plot_metrics(
                    score, y_test,
                    outname=os.path.join(args.outdir, "event{}_roc_{}.pdf".format(evtid, i)),
                    off_interactive=True
                )
                nx_filename = os.path.join(args.outdir, "event{}_nx_{}.pkl".format(evtid, i))
                if os.path.exists(nx_filename):
                    G = nx.read_gpickle(nx_filename)
                else:
                    G = utils.np_to_nx(array, event.hits)
                    nx.write_gpickle(G, nx_filename)
                _, ax = plt.subplots(figsize=(8, 8))
                #utils_plot.plot_nx_with_edge_cmaps(G, weight_name='weight', threshold=0.01, cmaps=plt.get_cmap("bwr"), alpha=0.5, ax=ax)
                utils_plot.plot_nx_with_edge_cmaps(G, weight_name='weight', threshold=0.01, ax=ax)
                plt.savefig(os.path.join(args.outdir, "event{}_display_all_{}.png".format(evtid, i)))
                del ax
                # do truth
                G1 = nx.Graph()
                G1.add_nodes_from(G.nodes(data=True))
                G1.add_edges_from([edge for edge in G.edges(data=True) if edge[2]['solution'] == 1])
                _, ax = plt.subplots(figsize=(8, 8))
                utils_plot.plot_nx_with_edge_cmaps(G1, weight_name='weight', threshold=0.01, ax=ax, cmaps=plt.get_cmap("gray"))
                plt.savefig(os.path.join(args.outdir, "event{}_display_truth_{}.png".format(evtid, i)))
                del ax
                # do fake 
                G2 = nx.Graph()
                G2.add_nodes_from(G.nodes(data=True))
                G2.add_edges_from([edge for edge in G.edges(data=True) if edge[2]['solution'] == 0])
                _, ax = plt.subplots(figsize=(8, 8))
                utils_plot.plot_nx_with_edge_cmaps(G2, weight_name='weight', threshold=0.01, ax=ax, cmaps=plt.get_cmap("Greys"))
                plt.savefig(os.path.join(args.outdir, "event{}_display_fake_{}.png".format(evtid, i)))
                del ax
                plt.close("all")

    outputs_te = utils_tf.concat(outputs_te_list, axis=0)
    targets_te = utils_tf.concat(targets_te_list, axis=0)
    prediction = tf.reshape(outputs_te.edges, (-1,))
    y_test = tf.reshape(targets_te.edges, (-1, ))
    plot_metrics(
        prediction, y_test,
        outname=os.path.join(args.outdir, "roc.pdf"),
        off_interactive=True
        )